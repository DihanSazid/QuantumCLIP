{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rXYdp40XlSB",
        "outputId": "617b2c2a-7123-4413-cb25-eb14720390fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.39.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.39 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.12.14)\n",
            "Downloading PennyLane-0.39.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.39.0 pennylane-lightning-0.39.0 rustworkx-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dAp-gNmX6_X",
        "outputId": "4efb5bb6-3a47-4bee-e26c-c7e79de576cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.6.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.25.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cu121)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=d1ea1ba0a0f5716d9ff7616ffa643a8f56dc184bc8ce55260fc812a9fc4b76b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms, models\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "import copy\n",
        "from medmnist import INFO\n",
        "import medmnist\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Quantum Circuit Configuration\n",
        "n_qubits = 4\n",
        "q_depth = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def qnode(inputs, weights):\n",
        "    weights = weights.view(q_depth, 2 * n_qubits)\n",
        "    for layer in range(q_depth):\n",
        "        for i in range(n_qubits):\n",
        "            qml.RY(weights[layer, i], wires=i)\n",
        "        for i in range(n_qubits):\n",
        "            qml.CRX(weights[layer, n_qubits + i], wires=[i, (i + 1) % n_qubits])\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "# Custom QuantumCLIP Model\n",
        "class QuantumCLIP(nn.Module):\n",
        "    def __init__(self, latent_dim=128, n_qubits=4, q_depth=4):\n",
        "        super(QuantumCLIP, self).__init__()\n",
        "        self.text_encoder = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        self.text_projection = nn.Linear(self.text_encoder.config.text_config.hidden_size, latent_dim, bias=True)\n",
        "\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.image_encoder = nn.Sequential(\n",
        "            *list(resnet.children())[:-2],\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.pre_net = nn.Linear(512, n_qubits)\n",
        "        self.pre_norm = nn.LayerNorm(n_qubits)\n",
        "        self.q_params = nn.Parameter(torch.randn(q_depth, 2 * n_qubits) * 0.01)\n",
        "        self.post_net = nn.Linear(n_qubits, latent_dim, bias=True)\n",
        "        self.skip_projection = nn.Linear(n_qubits, latent_dim, bias=True)\n",
        "\n",
        "    def forward(self, text_inputs, images):\n",
        "        text_embeddings = self.text_encoder.get_text_features(**text_inputs)\n",
        "        text_latent = self.text_projection(text_embeddings)\n",
        "\n",
        "        image_features = self.image_encoder(images)\n",
        "        image_features = image_features.view(image_features.size(0), -1)\n",
        "\n",
        "        pre_out = self.pre_net(image_features)\n",
        "        pre_out = self.pre_norm(pre_out)\n",
        "        q_in = torch.tanh(pre_out) * np.pi\n",
        "\n",
        "        q_out = torch.stack([torch.tensor(qnode(q_in[i], self.q_params)).float() for i in range(len(q_in))]).to(device)\n",
        "        skip_out = self.skip_projection(pre_out)\n",
        "        image_latent = self.post_net(q_out) + skip_out\n",
        "\n",
        "        return text_latent, image_latent\n",
        "\n",
        "# MedMNIST Dataset Loader\n",
        "class MedMNISTDataset(Dataset):\n",
        "    def __init__(self, split, transform=None):\n",
        "        info = INFO[\"pathmnist\"]\n",
        "        self.data_flag = \"pathmnist\"\n",
        "        self.task = info[\"task\"]\n",
        "        self.n_channels = info[\"n_channels\"]\n",
        "        self.n_classes = len(info[\"label\"])\n",
        "        self.class_names = {int(k): v for k, v in info[\"label\"].items()}\n",
        "\n",
        "        DataClass = getattr(medmnist, info[\"python_class\"])\n",
        "        self.data = DataClass(split=split, download=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.data[idx]\n",
        "        if isinstance(label, np.ndarray):\n",
        "            label = label.item()\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        text = f\"This is a {self.class_names[label]}.\"\n",
        "        return img, text, label\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        for phase in [\"train\", \"validation\"]:\n",
        "            model.train() if phase == \"train\" else model.eval()\n",
        "\n",
        "            total_loss = 0.0\n",
        "            total_corrects = 0\n",
        "            total_samples = 0\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "\n",
        "            for images, texts, labels in dataloaders[phase]:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                text_inputs = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")(\n",
        "                    text=texts, return_tensors=\"pt\", padding=True, truncation=True\n",
        "                )\n",
        "                text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    text_latent, image_latent = model(text_inputs, images)\n",
        "                    logits = torch.matmul(F.normalize(text_latent), F.normalize(image_latent).T)\n",
        "                    targets = torch.arange(len(logits)).to(device)\n",
        "                    loss = criterion(logits, targets)\n",
        "\n",
        "                    _, preds = torch.max(logits, 1)\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "                        optimizer.step()\n",
        "\n",
        "\n",
        "                total_loss += loss.item() * images.size(0)  # Scale loss by batch size\n",
        "                total_corrects += torch.sum(preds == labels.data).item()\n",
        "                total_samples += labels.size(0)\n",
        "\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "            epoch_loss = total_loss / total_samples\n",
        "            epoch_acc = total_corrects / total_samples\n",
        "            epoch_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, F1-Score: {epoch_f1:.4f}\")\n",
        "\n",
        "\n",
        "            if phase == \"validation\" and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            if phase == \"train\":\n",
        "                scheduler.step()\n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_cosine_sims = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, texts, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            text_inputs = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")(\n",
        "                text=texts, return_tensors=\"pt\", padding=True, truncation=True\n",
        "            )\n",
        "            text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
        "\n",
        "            text_latent, image_latent = model(text_inputs, images)\n",
        "\n",
        "\n",
        "            cosine_sim = F.cosine_similarity(text_latent, image_latent, dim=1)\n",
        "            all_cosine_sims.extend(cosine_sim.cpu().numpy())\n",
        "\n",
        "            logits = torch.matmul(F.normalize(text_latent), F.normalize(image_latent).T)\n",
        "            _, preds = torch.max(logits, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_cosine_sim = np.mean(all_cosine_sims)\n",
        "    avg_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    avg_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    avg_precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "    print(f\"Average Cosine Similarity: {avg_cosine_sim:.4f}\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
        "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
        "\n",
        "    return avg_accuracy, avg_f1, avg_precision\n",
        "\n",
        "# Main Script\n",
        "if __name__ == \"__main__\":\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = MedMNISTDataset(split=\"train\", transform=transform)\n",
        "    test_dataset = MedMNISTDataset(split=\"test\", transform=transform)\n",
        "\n",
        "    train_subset, _ = random_split(train_dataset, [500, len(train_dataset) - 500])\n",
        "    test_subset, _ = random_split(test_dataset, [100, len(test_dataset) - 100])\n",
        "\n",
        "    dataset_sizes = {\"train\": len(train_subset), \"validation\": len(test_subset)}\n",
        "\n",
        "    dataloaders = {\n",
        "        \"train\": DataLoader(train_subset, batch_size=16, shuffle=True),\n",
        "        \"validation\": DataLoader(test_subset, batch_size=16, shuffle=False)\n",
        "    }\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = QuantumCLIP(latent_dim=128, n_qubits=n_qubits, q_depth=q_depth).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
        "\n",
        "    model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=5)\n",
        "\n",
        "    avg_accuracy, avg_f1, avg_precision = evaluate_model(model, dataloaders[\"validation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv8fcagWnYc5",
        "outputId": "d3a8ab66-4c42-4de4-bf2c-d37404a44a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Train Loss: 2.4875, Accuracy: 0.0880, F1-Score: 0.1095\n",
            "Validation Loss: 2.3613, Accuracy: 0.0600, F1-Score: 0.0834\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train Loss: 2.3331, Accuracy: 0.0420, F1-Score: 0.0540\n",
            "Validation Loss: 2.3034, Accuracy: 0.0100, F1-Score: 0.0043\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train Loss: 2.2739, Accuracy: 0.0620, F1-Score: 0.0744\n",
            "Validation Loss: 2.2956, Accuracy: 0.0300, F1-Score: 0.0310\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train Loss: 2.2627, Accuracy: 0.0960, F1-Score: 0.1215\n",
            "Validation Loss: 2.2927, Accuracy: 0.0300, F1-Score: 0.0310\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train Loss: 2.2547, Accuracy: 0.0500, F1-Score: 0.0599\n",
            "Validation Loss: 2.2783, Accuracy: 0.0400, F1-Score: 0.0366\n",
            "Average Cosine Similarity: 0.4810\n",
            "Average Accuracy: 0.0600\n",
            "Average F1-Score: 0.0834\n",
            "Average Precision: 0.1655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jclWXtEvnYRg"
      }
    }
  ]
}